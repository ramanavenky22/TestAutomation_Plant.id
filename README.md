## TestAutomation_Plant.id

Automated test script for the Plant.id API (plant disease identification).  
The script reads test cases from a CSV file, sends images to the Plant.id API, compares predictions to expected labels, and writes detailed results to another CSV for analysis and reporting.

---

### Project Structure

- `test_automate.py` – main Python automation script.
- `plant_ai_test_cases.csv` – input test data.
- `plant_ai_test_results.csv` – output results (generated by the script).
- `images/` – folder containing test images (you create this).

Example layout:

```text
TestAutomation_Plant.id/
  test_automate.py
  plant_ai_test_cases.csv
  images/
    test1.jpg
    test2.jpg
```

---

### Prerequisites

- Python 3.8+ installed (`python --version`).
- `pip` available.
- A valid **Plant.id API key**.
- Internet access.

Install the Python dependency:

```bash
cd "C:\Users\018198674.SJSUAD.001\Desktop\TestAutomation_Plant.id"
pip install requests
```

---

### Configuration

Open `test_automate.py` and set:

- **API endpoint** (Plant.id):

```python
API_ENDPOINT = "https://www.plant.id/api_frontend/identify"
```

- **API key**:

```python
API_KEY = "YOUR_REAL_PLANT_ID_API_KEY"
```

Save the file.

---

### Test Case CSV (`plant_ai_test_cases.csv`)

The CSV drives which tests are executed. It must have this header:

```text
test_id,image_path,expected_label
```

- **test_id** – unique identifier for the test case (e.g. `TC01`).
- **image_path** – path to the image file, relative to the project root (e.g. `images/test1.jpg`).
- **expected_label** – the expected disease label, matching what Plant.id returns in
  `result.disease.suggestions[*].name` (e.g. `Fungi`, `nutrient deficiency`).

Example:

```text
test_id,image_path,expected_label
TC01,images/test1.jpg,Fungi
TC02,images/test2.jpg,nutrient deficiency
```

---

### What the Script Does

For each row in `plant_ai_test_cases.csv`, `test_automate.py` will:

1. Read `test_id`, `image_path`, and `expected_label`.
2. Load the image, encode it as base64, and send it to the Plant.id API with:
   - `classification_level = "all"`
   - `health = "all"`
   - `similar_images = true`
   - `symptoms = true`
3. Read the **disease predictions** from `result.disease.suggestions`.
4. Select the suggestion with the **highest probability**.
5. Compare the predicted disease name against `expected_label`.
6. Measure response latency.
7. Log all details to `plant_ai_test_results.csv`.

---

### Running the Tests

From the project directory:

```bash
python test_automate.py
```

During execution, the script prints for each test:

- Test ID and image path.
- Expected disease label.
- Predicted disease label and confidence (probability).
- PASS/FAIL based on the comparison.
- Latency in seconds.
- Any error message (e.g., missing file, HTTP error).

---

### Output: `plant_ai_test_results.csv`

Each test run generates/overwrites `plant_ai_test_results.csv` with columns:

- `timestamp`
- `test_id`
- `image_path`
- `expected_label`
- `predicted_label`
- `confidence`
- `pass` (True/False)
- `latency_sec`
- `error`
- `raw_response_snippet` (truncated JSON response)

You can open this in Excel or another spreadsheet tool to compute accuracy, coverage, and to support your test automation report (test strategies, execution results, costs, and complexity).

---

### Troubleshooting

- **Image file not found**
  - Check that `image_path` in the CSV matches the actual file location.
- **Authentication / 4xx errors**
  - Verify the endpoint URL and that `API_KEY` is valid.
- **Network / timeout issues**
  - Confirm internet connectivity.
  - Increase the timeout in `requests.post(..., timeout=30)` if necessary.

This README can be included directly as part of your Deliverable #3 documentation to explain how to set up and run your automated Plant.id API tests.